{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52b18466-ca1c-43a3-b10b-f96bed12cc73",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import groupby\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "import zlib\n",
    "import base64\n",
    "  \n",
    "def round_numeric_values(dictionary, sig):\n",
    "    rounded_dict = {}\n",
    "    for key, value in dictionary.items():\n",
    "        if isinstance(value, (int, float)):\n",
    "            rounded_dict[key] = round(value, sig)\n",
    "        elif isinstance(value, list):\n",
    "            rounded_dict[key] = [round(element, sig) if isinstance(element, (int, float)) else element for element in value]\n",
    "        else:\n",
    "            rounded_dict[key] = value\n",
    "    return rounded_dict\n",
    "\n",
    "def create_composite_dict(df,numeric_precision):\n",
    "    data_list = df.to_dict('records')\n",
    "    d = defaultdict(dict)\n",
    "    # Sort the data_list by the 'mergeon' field\n",
    "    data_list.sort(key=lambda x: x['mergeon'])\n",
    "    # Group the data_list by 'authfull' and 'mergeon'\n",
    "    for (authfull, mergeon), group in groupby(data_list, key=lambda x: (x['sm-field'], x['mergeon'])):\n",
    "        # Extract the relevant fields\n",
    "        selected_data = [{k: v for k, v in entry.items() if k not in ['sm-field', 'mergeon']} for entry in group]\n",
    "        d[authfull][mergeon] = round_numeric_values(selected_data[0],numeric_precision)\n",
    "    result_dict = dict(d)\n",
    "    return result_dict\n",
    "\n",
    "def standardize_col_names(df, year, v1_present = False, singleyr = False):\n",
    "    generic_cols = ['authfull', 'inst_name', 'cntry', 'np', 'firstyr', 'lastyr','rank (ns)', 'nc (ns)', 'h (ns)', 'hm (ns)', 'nps (ns)','ncs (ns)', 'cpsf (ns)', \n",
    "                  'ncsf (ns)', 'npsfl (ns)', 'ncsfl (ns)','c (ns)', 'npciting (ns)', 'cprat (ns)', 'np cited (ns)','self%', 'rank', 'nc', 'h', 'hm', \n",
    "                  'nps', 'ncs', 'cpsf', 'ncsf','npsfl', 'ncsfl', 'c', 'npciting', 'cprat', 'np cited','np_d', 'nc_d', 'sm-subfield-1', 'sm-subfield-1-frac',\n",
    "                  'sm-subfield-2', 'sm-subfield-2-frac', 'sm-field', 'sm-field-frac','rank sm-subfield-1', 'rank sm-subfield-1 (ns)', 'sm-subfield-1 count']\n",
    "    generic_cols_text = [f'author name',f'institution name (large institutions only)',f'country associated with most recent institution',f'number of papers from 1960 to {year})',\n",
    "                       f'year of first publication',f'year of most recent publication',f'rank based on composite score c',f'total cites from 1996 to {year}',\n",
    "                       f'h-index as of the end of {year}',f'hm-index as of end-{year}',f'number of single authored papers',f'total cites to single authored papers',\n",
    "                       f'number of single + first authored papers',f'total cites to single + first authored papers',f'number of single + first + last authored papers',\n",
    "                       f'total cites to single + first + last authored papers',f'composite score',f'number of distinct citing papers',\n",
    "                       f'ratio of total citations to distinct citing papers',f'number of papers 1960-{year} that have been cited at least once (1996-{year})',\n",
    "                       f'self-citation percentage',f'rank based on composite score c',f'total cites 1996-{year}',f'h-index as of end-{year}',\n",
    "                       f'hm-index as of end-{year}',f'number of single authored papers',f'total cites to single authored papers',\n",
    "                       f'number of single + first authored papers',f'total cites to single + first authored papers',f'number of single + first + last authored papers',\n",
    "                       f'total cites to single + first + last authored papers',f'composite score',f'number of distinct citing papers',\n",
    "                       f'ratio of total citations to distinct citing papers',f'number of papers 1960-{year} that have been cited at least once (1996-{year})',\n",
    "                       f'# papers 1960-{year} in titles that are discontinued in Scopus',f'total cites 1996-{year} from titles that are discontinued in Scopus',\n",
    "                       f'top ranked Science-Metrix category (subfield) for author',f'associated category fraction',f'second ranked Science-Metrix category (subfield) for author',\n",
    "                       f'associated category fraction',f'top ranked higher-level Science-Metrix category (field) for author',\n",
    "                       f'associated category fraction',f'rank of c within category sm-subfield-1',f'rank of c (ns) within category sm-subfield-1',\n",
    "                       f'total number of authors within category sm-subfield-1']\n",
    "    if not v1_present: \n",
    "        df.columns = generic_cols\n",
    "        return(df,dict(zip(generic_cols, generic_cols_text))) # len(generic_cols_text) = 46\n",
    "    else:\n",
    "        remove_cols = ['np cited (ns)','np cited','np_d','nc_d','rank sm-subfield-1','rank sm-subfield-1 (ns)','sm-subfield-1 count']\n",
    "        remove_text = [f'number of papers 1960-{year} that have been cited at least once (1996-{year})',f'number of papers 1960-{year} that have been cited at least once (1996-{year})',f'# papers 1960-{year} in titles that are discontinued in Scopus',f'total cites 1996-{year} from titles that are discontinued in Scopus',f'rank of c within category sm-subfield-1',f'rank of c (ns) within category sm-subfield-1',f'total number of authors within category sm-subfield-1']\n",
    "\n",
    "        if year == 2017 or year == 2018:\n",
    "            df = df.drop(columns = ['sm-1', 'sm-2','sm22'])\n",
    "            if singleyr and year == 2017: # singleyr 2017 missing 2 columns!\n",
    "                remove_cols += 'firstyr','lastyr' \n",
    "                remove_text += f'year of first publication',f'year of most recent publication'\n",
    "            for item in remove_cols: generic_cols.remove(item)\n",
    "            for item in remove_text: generic_cols_text.remove(item)\n",
    "            df.columns = generic_cols\n",
    "        else:\n",
    "            df.columns = generic_cols\n",
    "            for item in remove_cols: generic_cols.remove(item)\n",
    "            for item in remove_text: generic_cols_text.remove(item)\n",
    "            df = df.drop(columns = remove_cols)\n",
    "        return(df,dict(zip(generic_cols, generic_cols_text))) # len(generic_cols_text) = 39 (37 for singleyr 2017)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43bf6eb-1a6f-44ba-bd6f-146461e0919e",
   "metadata": {},
   "source": [
    "## Career data\n",
    "\n",
    "* Log and normal\n",
    "* Grouped by author name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2acaebf7-a1a4-4245-9af0-33d56412b238",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "career_sheets = ['Table-S1-career-2017', 'Table-S4-career-2018', 'Table-S6-career-2019', 'Table_1_Authors_career_2020_wopp_extracted_202108',\n",
    "    'Table_1_Authors_career_2021_pubs_since_1788_wopp_extracted_202209b']\n",
    "career_sheets_keys = ['career_2017','career_2018','career_2019','career_2020','career_2021']\n",
    "\n",
    "career_yrs = [2017, 2018, 2019, 2020, 2021]\n",
    "singleyr_yrs = [2017, 2019, 2020, 2021]\n",
    "career_versions = [1,1,2,3,5]\n",
    "singleyr_versions = [1,2,3,5]\n",
    "\n",
    "dfs_career = pd.DataFrame()\n",
    "dfs_career_log = pd.DataFrame()\n",
    "for sheet, version,year in zip(career_sheets, career_versions,career_yrs):\n",
    "    cur_nor = pd.read_pickle('data/version-' + str(version) + '/' + sheet + '.pkl').replace(np.nan,'')\n",
    "    cur_nor = standardize_col_names(df = cur_nor, year = year, v1_present = True, singleyr = False)\n",
    "    cur_nor[0]['mergeon'] = f\"career_{year}\"\n",
    "    cur_log = pd.read_pickle('data/version-' + str(version) + '/' + sheet + '_LogTransform.pkl').replace(np.nan,'')\n",
    "    cur_log = standardize_col_names(df = cur_log, year = year, v1_present = True, singleyr = False)\n",
    "    cur_log[0]['mergeon'] = f\"career_{year}_log\"\n",
    "    dfs_career = pd.concat([dfs_career, cur_nor[0]], ignore_index=True, sort=False)  \n",
    "    dfs_career = pd.concat([dfs_career, cur_log[0]], ignore_index=True, sort=False)\n",
    "\n",
    "career_composite = create_composite_dict(dfs_career,3)\n",
    "pickle.dump(career_composite, open(\"career_composite2.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb5b9a3-c641-4eb6-9bab-f39b9961ee75",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Single year data\n",
    "\n",
    "* Log and normal\n",
    "* Grouped by author name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c7b89947-9064-475a-ae2b-0ae2dc63f0f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "singleyr_sheets = ['Table-S2-singleyr-2017', 'Table-S7-singleyr-2019', 'Table_1_Authors_singleyr_2020_wopp_extracted_202108',\n",
    "    'Table_1_Authors_singleyr_2021_pubs_since_1788_wopp_extracted_202209b']\n",
    "\n",
    "singleyr_yrs = [2017, 2019, 2020, 2021]\n",
    "singleyr_versions = [1,2,3,5]\n",
    "# dfs_singleyr = []\n",
    "# dfs_singleyr_log = []\n",
    "dfs_singleyr = pd.DataFrame()\n",
    "dfs_singleyr_log = pd.DataFrame()\n",
    "for sheet, version,year in zip(singleyr_sheets, singleyr_versions,singleyr_yrs):\n",
    "    cur_nor = pd.read_pickle('data/version-' + str(version) + '/' + sheet + '.pkl').replace(np.nan,'')\n",
    "    cur_nor = standardize_col_names(df = cur_nor, year = year, v1_present = True, singleyr = True)\n",
    "    cur_nor[0]['mergeon'] = f\"singleyr_{year}\"\n",
    "    cur_log = pd.read_pickle('data/version-' + str(version) + '/' + sheet + '_LogTransform.pkl').replace(np.nan,'')\n",
    "    cur_log = standardize_col_names(df = cur_log, year = year, v1_present = True, singleyr = True)\n",
    "    cur_log[0]['mergeon'] = f\"singleyr_{year}_log\"\n",
    "    dfs_singleyr = pd.concat([dfs_singleyr, cur_nor[0]], ignore_index=True, sort=False)\n",
    "    dfs_singleyr = pd.concat([dfs_singleyr, cur_log[0]], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f585af03-7dcd-4c18-8e38-a951b659f90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "singleyr_composite = create_composite_dict(dfs_singleyr,3)\n",
    "pickle.dump(singleyr_composite, open(\"composite_singleyr.p\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
